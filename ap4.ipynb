{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"IPf0LmDijQLt"},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"code","source":["from google.colab import drive\n","#drive.flush_and_unmount()\n","drive.mount('/gdrive')\n"],"metadata":{"id":"i-CCwDgSjZ5s","executionInfo":{"status":"ok","timestamp":1650599780536,"user_tz":420,"elapsed":18950,"user":{"displayName":"Jinglan Liu","userId":"09247368686056095984"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"917eb78c-4efc-4e85-c0f8-c14ada21b0a7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n"]}]},{"cell_type":"code","source":["filepath = \"/gdrive/MyDrive/info_159_Project/ap4\""],"metadata":{"id":"Wo3t8rzmvrnt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dev = pd.read_csv(filepath + \"/dev.txt\", sep = \"\\t\", header=None)\n","dev"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"-Ne9tT1FkKBp","executionInfo":{"status":"ok","timestamp":1650599797726,"user_tz":420,"elapsed":1064,"user":{"displayName":"Jinglan Liu","userId":"09247368686056095984"}},"outputId":"e523d93c-1cc1-4edd-a47d-822a19cf57e6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       0       1                                                  2\n","0    802    high  ---------------------- Forwarded by Vince J Ka...\n","1    793     low  We need to get something for Ina for Admin Ass...\n","2    859  medium  Where have you been? What type of camera was it??\n","3    612     low  We do not keep inventory schedules on any of t...\n","4     47  medium  hey jason, how is the new job? shanna and I wo...\n","..   ...     ...                                                ...\n","195   86  medium  Yeah, the question is waht kind of good partie...\n","196   73     low  ---------------------- Forwarded by Vince J Ka...\n","197  690  medium  Here is the latest contact list. I added a cou...\n","198   34  medium  We want to have an internal conference call at...\n","199  994     low  Hi Terry - Ken Lay said that he would really l...\n","\n","[200 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-3a27703f-62ec-4d89-997c-60f3a0c40be9\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>802</td>\n","      <td>high</td>\n","      <td>---------------------- Forwarded by Vince J Ka...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>793</td>\n","      <td>low</td>\n","      <td>We need to get something for Ina for Admin Ass...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>859</td>\n","      <td>medium</td>\n","      <td>Where have you been? What type of camera was it??</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>612</td>\n","      <td>low</td>\n","      <td>We do not keep inventory schedules on any of t...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>47</td>\n","      <td>medium</td>\n","      <td>hey jason, how is the new job? shanna and I wo...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>195</th>\n","      <td>86</td>\n","      <td>medium</td>\n","      <td>Yeah, the question is waht kind of good partie...</td>\n","    </tr>\n","    <tr>\n","      <th>196</th>\n","      <td>73</td>\n","      <td>low</td>\n","      <td>---------------------- Forwarded by Vince J Ka...</td>\n","    </tr>\n","    <tr>\n","      <th>197</th>\n","      <td>690</td>\n","      <td>medium</td>\n","      <td>Here is the latest contact list. I added a cou...</td>\n","    </tr>\n","    <tr>\n","      <th>198</th>\n","      <td>34</td>\n","      <td>medium</td>\n","      <td>We want to have an internal conference call at...</td>\n","    </tr>\n","    <tr>\n","      <th>199</th>\n","      <td>994</td>\n","      <td>low</td>\n","      <td>Hi Terry - Ken Lay said that he would really l...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>200 rows Ã— 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3a27703f-62ec-4d89-997c-60f3a0c40be9')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3a27703f-62ec-4d89-997c-60f3a0c40be9 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3a27703f-62ec-4d89-997c-60f3a0c40be9');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["test = pd.read_csv(filepath + \"/test.txt\", sep = \"\\t\", header=None)\n","test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"WQ7veXbGkusS","executionInfo":{"status":"ok","timestamp":1650599798491,"user_tz":420,"elapsed":768,"user":{"displayName":"Jinglan Liu","userId":"09247368686056095984"}},"outputId":"20f3a553-729e-4084-85e7-23239682f5bb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       0       1                                                  2\n","0    565     low                                         Thanks! DF\n","1     94     low  Beavy and I changed the following deals for Ju...\n","2    186     low  Sean and Diana do not recognize this deal. The...\n","3    599     low  ---------------------- Forwarded by Eric Bass/...\n","4    564  medium  Hi, Elise. Sorry to bother you, but when Kali ...\n","..   ...     ...                                                ...\n","195  783     low  Lindy, You are correct they are physical plant...\n","196  822  medium  Thanks for the attached deal information, Shou...\n","197  868  medium  Tom, The system does not take my approval of t...\n","198  583     low  --------------------- Forwarded by Darron C Gi...\n","199  138     low  ---------------------- Forwarded by Kay Mann/C...\n","\n","[200 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-91b8a38d-87ff-4b2b-a535-7d68a3c3a941\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>565</td>\n","      <td>low</td>\n","      <td>Thanks! DF</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>94</td>\n","      <td>low</td>\n","      <td>Beavy and I changed the following deals for Ju...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>186</td>\n","      <td>low</td>\n","      <td>Sean and Diana do not recognize this deal. The...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>599</td>\n","      <td>low</td>\n","      <td>---------------------- Forwarded by Eric Bass/...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>564</td>\n","      <td>medium</td>\n","      <td>Hi, Elise. Sorry to bother you, but when Kali ...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>195</th>\n","      <td>783</td>\n","      <td>low</td>\n","      <td>Lindy, You are correct they are physical plant...</td>\n","    </tr>\n","    <tr>\n","      <th>196</th>\n","      <td>822</td>\n","      <td>medium</td>\n","      <td>Thanks for the attached deal information, Shou...</td>\n","    </tr>\n","    <tr>\n","      <th>197</th>\n","      <td>868</td>\n","      <td>medium</td>\n","      <td>Tom, The system does not take my approval of t...</td>\n","    </tr>\n","    <tr>\n","      <th>198</th>\n","      <td>583</td>\n","      <td>low</td>\n","      <td>--------------------- Forwarded by Darron C Gi...</td>\n","    </tr>\n","    <tr>\n","      <th>199</th>\n","      <td>138</td>\n","      <td>low</td>\n","      <td>---------------------- Forwarded by Kay Mann/C...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>200 rows Ã— 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-91b8a38d-87ff-4b2b-a535-7d68a3c3a941')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-91b8a38d-87ff-4b2b-a535-7d68a3c3a941 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-91b8a38d-87ff-4b2b-a535-7d68a3c3a941');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["train = pd.read_csv(filepath +  \"/train.txt\", sep = \"\\t\", header=None)\n","train"],"metadata":{"id":"PeE5x0uQlZFo","colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"status":"ok","timestamp":1650599798754,"user_tz":420,"elapsed":267,"user":{"displayName":"Jinglan Liu","userId":"09247368686056095984"}},"outputId":"dfb93507-f1b6-4b01-9adf-9b32126ddde3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       0       1                                                  2\n","0    853     low  http://gasfundy.corp.enron.com/gas/framework/d...\n","1    837     low  ---------------------- Forwarded by V Charles ...\n","2    281  medium  I just tried to call you. What is your parents...\n","3    576     low  ---------------------- Forwarded by Vince J Ka...\n","4    209     low  ---------------------- Forwarded by Vince J Ka...\n","..   ...     ...                                                ...\n","595  246  medium  I just wanted to let you know that I got out U...\n","596  760     low  FYI Vince ---------------------- Forwarded by ...\n","597  998  medium  Here it is. Let me know if you have any questi...\n","598  609     low         Kim is taking care of that invoice. Thanks\n","599  823    high  Susan, Are you clear on what you need to do wi...\n","\n","[600 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-64926ce2-8d2f-4888-a705-733657fac908\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>853</td>\n","      <td>low</td>\n","      <td>http://gasfundy.corp.enron.com/gas/framework/d...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>837</td>\n","      <td>low</td>\n","      <td>---------------------- Forwarded by V Charles ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>281</td>\n","      <td>medium</td>\n","      <td>I just tried to call you. What is your parents...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>576</td>\n","      <td>low</td>\n","      <td>---------------------- Forwarded by Vince J Ka...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>209</td>\n","      <td>low</td>\n","      <td>---------------------- Forwarded by Vince J Ka...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>595</th>\n","      <td>246</td>\n","      <td>medium</td>\n","      <td>I just wanted to let you know that I got out U...</td>\n","    </tr>\n","    <tr>\n","      <th>596</th>\n","      <td>760</td>\n","      <td>low</td>\n","      <td>FYI Vince ---------------------- Forwarded by ...</td>\n","    </tr>\n","    <tr>\n","      <th>597</th>\n","      <td>998</td>\n","      <td>medium</td>\n","      <td>Here it is. Let me know if you have any questi...</td>\n","    </tr>\n","    <tr>\n","      <th>598</th>\n","      <td>609</td>\n","      <td>low</td>\n","      <td>Kim is taking care of that invoice. Thanks</td>\n","    </tr>\n","    <tr>\n","      <th>599</th>\n","      <td>823</td>\n","      <td>high</td>\n","      <td>Susan, Are you clear on what you need to do wi...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>600 rows Ã— 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-64926ce2-8d2f-4888-a705-733657fac908')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-64926ce2-8d2f-4888-a705-733657fac908 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-64926ce2-8d2f-4888-a705-733657fac908');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["from scipy import sparse\n","from sklearn import linear_model\n","from collections import Counter\n","import numpy as np\n","import operator\n","import nltk\n","import math\n","from scipy.stats import norm"],"metadata":{"id":"0lPLUwtrnOb0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python -m nltk.downloader punkt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QNBJeEEKndEd","executionInfo":{"status":"ok","timestamp":1650599801166,"user_tz":420,"elapsed":1327,"user":{"displayName":"Jinglan Liu","userId":"09247368686056095984"}},"outputId":"fe3ab46d-4238-4884-e613-0b93b5011ef8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/lib/python3.7/runpy.py:125: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n","  warn(RuntimeWarning(msg))\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}]},{"cell_type":"code","source":["def load_ordinal_data(filename, ordering):\n","    X = []\n","    Y = []\n","    orig_Y=[]\n","    for ordinal in ordering:\n","        Y.append([])\n","        \n","    with open(filename, encoding=\"utf-8\") as file:\n","        for line in file:\n","            cols = line.split(\"\\t\")\n","            idd = cols[0]\n","            label = cols[1].lstrip().rstrip()\n","            text = cols[2]\n","\n","            X.append(text)\n","            \n","            index=ordering.index(label)\n","            for i in range(len(ordering)):\n","                if index > i:\n","                    Y[i].append(1)\n","                else:\n","                    Y[i].append(0)\n","            orig_Y.append(label)\n","                    \n","    return X, Y, orig_Y"],"metadata":{"id":"5Hxl75lGnfFo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class OrdinalClassifier:\n","\n","    def __init__(self, ordinal_values, feature_method, trainX, trainY, devX, devY, testX, testY, orig_trainY, orig_devY, orig_testY):\n","        self.ordinal_values=ordinal_values\n","        self.feature_vocab = {}\n","        self.feature_method = feature_method\n","        self.min_feature_count=2\n","        self.log_regs = [None]* (len(self.ordinal_values)-1)\n","\n","        self.trainY=trainY\n","        self.devY=devY\n","        self.testY=testY\n","        \n","        self.orig_trainY=orig_trainY\n","        self.orig_devY=orig_devY\n","        self.orig_testY=orig_testY\n","        \n","        self.trainX = self.process(trainX, training=True)\n","        self.devX = self.process(devX, training=False)\n","        self.testX = self.process(testX, training=False)\n","\n","    # Featurize entire dataset\n","    def featurize(self, data):\n","        featurized_data = []\n","        for text in data:\n","            feats = self.feature_method(text)\n","            featurized_data.append(feats)\n","        return featurized_data\n","\n","    # Read dataset and returned featurized representation as sparse matrix + label array\n","    def process(self, X_data, training = False):\n","        \n","        data = self.featurize(X_data)\n","\n","        if training:\n","            fid = 0\n","            feature_doc_count = Counter()\n","            for feats in data:\n","                for feat in feats:\n","                    feature_doc_count[feat]+= 1\n","\n","            for feat in feature_doc_count:\n","                if feature_doc_count[feat] >= self.min_feature_count:\n","                    self.feature_vocab[feat] = fid\n","                    fid += 1\n","\n","        F = len(self.feature_vocab)\n","        D = len(data)\n","        X = sparse.dok_matrix((D, F))\n","        for idx, feats in enumerate(data):\n","            for feat in feats:\n","                if feat in self.feature_vocab:\n","                    X[idx, self.feature_vocab[feat]] = feats[feat]\n","\n","        return X\n","\n","\n","    def train(self):\n","        (D,F) = self.trainX.shape\n","\n","        \n","        for idx, ordinal_value in enumerate(self.ordinal_values[:-1]):\n","            best_dev_accuracy=0\n","            best_model=None\n","            for C in [0.1, 1, 10, 100]:\n","\n","                log_reg = linear_model.LogisticRegression(C = C, max_iter=1000)\n","                # params for coefficience, print the param.\n","                log_reg.fit(self.trainX, self.trainY[idx])\n","                development_accuracy = log_reg.score(self.devX, self.devY[idx])\n","                if development_accuracy > best_dev_accuracy:\n","                    best_dev_accuracy=development_accuracy\n","                    best_model=log_reg\n","\n","\n","            self.log_regs[idx]=best_model\n","        \n","    def test(self):\n","        cor=tot=0\n","        counts=Counter()\n","        preds=[None]*(len(self.ordinal_values)-1)\n","        #print(\"preds\", preds)\n","        for idx, ordinal_value in enumerate(self.ordinal_values[:-1]):\n","            preds[idx]=self.log_regs[idx].predict_proba(self.testX)[:,1]\n","        \n","        preds=np.array(preds)\n","            \n","        for data_point in range(len(preds[0])):\n","            \n","    \n","            ordinal_preds=np.zeros(len(self.ordinal_values))\n","            for ordinal in range(len(self.ordinal_values)-1):\n","                if ordinal == 0:\n","                    ordinal_preds[ordinal]=1-preds[ordinal][data_point]\n","                else:\n","                    ordinal_preds[ordinal]=preds[ordinal-1][data_point]-preds[ordinal][data_point]\n","\n","            ordinal_preds[len(self.ordinal_values)-1]=preds[len(preds)-1][data_point]\n","\n","            prediction=np.argmax(ordinal_preds)\n","            counts[prediction]+=1\n","            if prediction == self.ordinal_values.index(self.orig_testY[data_point]):\n","                cor+=1\n","            tot+=1\n","\n","        return cor/tot\n","    \n","\n","    def prediction(self):\n","      counts=Counter()\n","      preds=[None]*(len(self.ordinal_values)-1)\n","      for idx, ordinal_value in enumerate(self.ordinal_values[:-1]):\n","          preds[idx]=self.log_regs[idx].predict_proba(self.testX)[:,1]\n","        \n","      preds=np.array(preds)\n","      predictions = []\n","            \n","      for data_point in range(len(preds[0])):\n","            \n","    \n","          ordinal_preds=np.zeros(len(self.ordinal_values))\n","          for ordinal in range(len(self.ordinal_values)-1):\n","              if ordinal == 0:\n","                  ordinal_preds[ordinal]=1-preds[ordinal][data_point]\n","              else:\n","                  ordinal_preds[ordinal]=preds[ordinal-1][data_point]-preds[ordinal][data_point]\n","\n","          ordinal_preds[len(self.ordinal_values)-1]=preds[len(preds)-1][data_point]\n","\n","          prediction=np.argmax(ordinal_preds) #Returns the indices of the maximum values along an axis\n","          predictions.append(prediction)\n","          counts[prediction]+=1\n","      return counts, predictions\n","      \n"],"metadata":{"id":"N6un-42inhVL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def binary_bow_featurize(text):\n","    feats = {}\n","    words = nltk.word_tokenize(text)\n","\n","    for word in words:\n","        word=word.lower()\n","        feats[word]=1\n","            \n","    return feats"],"metadata":{"id":"LQ-JxnNHnmG9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def feature1(text):\n","  feats = {}\n","  words = nltk.word_tokenize(text)\n","  for i in range(len(words)-1):\n","      word1 = words[i].lower()\n","      word2 = words[i + 1].lower()\n","      feats[word1 + \" \" + word2] = 1\n","  return feats"],"metadata":{"id":"q_DJa0kc1O6A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["feature1(\"this is a test\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"COwJ90tDlwsi","executionInfo":{"status":"ok","timestamp":1650599801675,"user_tz":420,"elapsed":19,"user":{"displayName":"Jinglan Liu","userId":"09247368686056095984"}},"outputId":"4e9e921b-9b92-4973-e4b6-0cc2264c4871"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'a test': 1, 'is a': 1, 'this is': 1}"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["high = [\"asap\", \"password\", \"suggestion\", \"think\", \"userid\", \"can\"]\n","medium = [\"looking\", \"send\", \"reply\", \"forward\", \"let\"]\n","low = [\"call\", \"no\", \"haha\", \"fyi\", \"note\", \"pls\", \"thanks\", \"link\", \"www\"]"],"metadata":{"id":"HqK2XS4g26ct"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def feature2(text):\n","  feats = {}\n","  words = nltk.word_tokenize(text)\n","  for word in words:\n","    word = word.lower()\n","    if word in high:\n","      if \"high\" in feats:\n","        feats[\"high\"] = feats[\"high\"] + 1\n","      else:\n","        feats[\"high\"] = 1\n","    if word in medium:\n","      if \"medium\" in feats:\n","        feats[\"medium\"] = feats[\"medium\"] + 1\n","      else:\n","        feats[\"meidum\"] = 1\n","    if word in low:\n","      if \"low\" in feats:\n","        feats[\"low\"] = feats[\"low\"] + 1\n","      else:\n","        feats[\"low\"] = 1\n","  return feats"],"metadata":{"id":"tyYuA6Wa1Z44"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["high = [\"asap\", \"password\", \"suggestion\", \"think\", \"userid\", \"can\"]\n","medium = [\"looking\", \"send\", \"reply\", \"forward\", \"let\"]\n","#low = [\"call\", \"no\", \"haha\", \"fyi\", \"note\", \"pls\", \"thanks\", \"link\", \"www\"]"],"metadata":{"id":"OEep1aFZvTpJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def feature3(text):\n","  feats = {}\n","  words = nltk.word_tokenize(text)\n","  for word in words:\n","    if word in high:\n","      feats[\"high\"] = 1\n","    if word in medium:\n","      feats[\"medium\"] = 1\n","    else:\n","      feats[\"low\"] = 1"],"metadata":{"id":"OUb2RcFYvO4O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generate_N_grams(text,ngram=1):\n","  words=[word for word in text.split(\" \")]  \n","  temp=zip(*[words[i:] for i in range(0,ngram)])\n","  ans=[' '.join(ngram) for ngram in temp]\n","  return ans"],"metadata":{"id":"aDT_qiYmJbs_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def time_featurize(text):\n","    feats = {}\n","    feats['bias_term']=1\n","    words = nltk.word_tokenize(text.lower())\n","    timesensitive_uni = [\"asap\",\"now\",\"deadline\",\"now\",\"urgent\"]\n","    timesensitive_bi = [\"done by\",\"have by\",\"send by\",\"right now\"]\n","    for word in words:\n","      if word in timesensitive_uni:\n","        feats['timesensitive'] = 1\n","    for bi in generate_N_grams(text.lower(),2):\n","      if bi in timesensitive_bi:\n","        feats['timesensitive'] = 1      \n","    return feats"],"metadata":{"id":"0A0_wuD7JVwj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def tech_featurize(text):\n","    feats = {}\n","    \n","    words = nltk.word_tokenize(text.lower())\n","    tech_uni = [\"password\",\"login\",\"system\",\"urgent\"]\n","    tech_bi = [\"log in\",\"user id\",\"forgot password\",\"system update\",\"doesn't work\"]\n","    for word in words:\n","      if word in tech_uni:\n","        feats['techissue'] = 1\n","    for bi in generate_N_grams(text.lower(),2):\n","      if bi in tech_bi:\n","        feats['techissue'] = 1      \n","    return feats"],"metadata":{"id":"HFlhU7K6JYZK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def prof_featurize(text):\n","    feats = {}\n","    \n","    words = nltk.word_tokenize(text.lower())\n","    prof_uni = [\"case\",\"deal\",\"client\",\"trade\",\"contract\"]\n","    prof_bi = [\"could you\"]\n","    for word in words:\n","      if word in prof_uni:\n","        feats['prof'] = 1\n","    for bi in generate_N_grams(text.lower(),2):\n","      if bi in prof_bi:\n","        feats['prof'] = 1      \n","    return feats"],"metadata":{"id":"-7ZBBnXyJc9L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def question_featurize(text):\n","    feats = {}\n","    \n","    words = nltk.word_tokenize(text.lower())\n","    ques_uni = [\"?\",\"help\",\"favor\",\"what\",\"when\",\"know\",\"how\",\"why\",\"where\"]\n","    ques_bi = [\"could you\",\"do you\",\"what is\",\"can you\",\"is that\"]\n","    for word in words:\n","      if word in ques_uni:\n","        feats['question'] = 1\n","    for bi in generate_N_grams(text.lower(),2):\n","      if bi in ques_bi:\n","        feats['question'] = 1      \n","    return feats"],"metadata":{"id":"A0oqFkSUJhMX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def opinions_featurize(text):\n","    feats = {}\n","  \n","    words = nltk.word_tokenize(text.lower())\n","    op_bi = [\"have suggestions\",\"your opinion\",\"your thoughts\",\"your suggestion\",\"offer suggestion\"]\n","\n","    op_tri = [\"have any suggestions\",\"what's your thought\",\"what you think\",\"thoughts on\"]\n","    for bi in generate_N_grams(text.lower(),2):\n","      if bi in op_bi:\n","        feats['opinion'] = 1\n","    for tri in generate_N_grams(text.lower(),3):\n","      if tri in op_tri:\n","        feats['opinion'] = 1      \n","    return feats"],"metadata":{"id":"K8pbf0cmJjKE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def action_featurize(text):\n","    feats = {}\n","  \n","    words = nltk.word_tokenize(text.lower())\n","    action_uni = [\"send\",\"receive\",\"copy\",\"respond\",\"reply\"]\n","    for word in words:\n","      if word in action_uni:\n","        feats['action'] = 1    \n","    return feats"],"metadata":{"id":"TBG0n60IJlbX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def casual_featurize(text):\n","    feats = {}\n","  \n","    words = nltk.word_tokenize(text.lower())\n","    casual_uni = [\"haha\",\"lol\",\"lmao\",\"wtf\",\"wth\",\"hell\",\"fuck\",\"damn\",\"sorta\"]\n","    casual_bi = [\"sort of\",\"what's up\"]\n","    for word in words:\n","      if word in casual_uni:\n","        feats['casual'] = 1\n","    for bi in generate_N_grams(text.lower(),2):\n","      if bi in casual_bi:\n","        feats['casual'] = 1      \n","    return feats"],"metadata":{"id":"7_C1BCkVJngK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def personal_featurize(text):\n","    feats = {}\n","  \n","    words = nltk.word_tokenize(text.lower())\n","    personal_uni = [\"reunion\",\"how's\"]\n","    personal_bi = [\"hang out\",\"how's life\",\"catch up\",\"get together\"]\n","    for word in words:\n","      if word in personal_uni:\n","        feats['personal'] = 1\n","    for bi in generate_N_grams(text.lower(),2):\n","      if bi in personal_bi:\n","        feats['personal'] = 1      \n","    return feats"],"metadata":{"id":"6Cpt5sInJpt9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def low_featurize(text):\n","    feats = {}\n","  \n","    words = nltk.word_tokenize(text.lower())\n","    low_uni = [\"print\",\"text\",\"fyi\",\"file\",\"resend\"]\n","    low_bi = [\"call me\",\"good job\",\"my comment\"]\n","    for word in words:\n","      if word in low_uni:\n","        feats['low'] = 1\n","    for bi in generate_N_grams(text.lower(),2):\n","      if bi in low_bi:\n","        feats['low'] = 1      \n","    return feats"],"metadata":{"id":"kM3XhtH8Jrr6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def medium_featurize(text):\n","    feats = {}\n","\n","    words = nltk.word_tokenize(text.lower())\n","    med_5 = [\"unless anyone has other opinions\",\"looking forward to your response\"]\n","    med_7 = [\"let me know if there's any question\",\"looking forward to hearing back from you\"]\n","    med_11 = [\"if you have any other question, reply to this email\"]\n","    for five in generate_N_grams(text.lower(),5):\n","      if five in med_5:\n","        feats['med'] = 1   \n","    for seven in generate_N_grams(text.lower(),7):\n","      if seven in med_7:\n","        feats['med'] = 1\n","    for eleven in generate_N_grams(text.lower(),11):\n","      if eleven in med_11:\n","        feats['med'] = 1           \n","    return feats"],"metadata":{"id":"b8GNabFbJuXg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# def feature3(text):\n","#     feats = {}\n","#     feats['bias_term']=1\n","#     words = nltk.word_tokenize(text.lower())\n","#     # timesensitive = [\"asap\",\"now\",\"finish by\",\"done by\",\"send by\",\"deadline\",\"right now\"]\n","#     trigrams = nltk.trigrams(words)\n","#     for trigram in trigrams:\n","#       feats[] = 1\n","            \n","#     return feats"],"metadata":{"id":"aMKulo0z8dFS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# trigrams = nltk.trigrams()"],"metadata":{"id":"_EFAL9709VWS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# def feature3(text):\n","#   return None"],"metadata":{"id":"oxclDjdX1ch6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def combiner_function(text):\n","\n","    # Here the `all_feats` dict should contain the features -- the key should be the feature name, \n","    # and the value is the feature value.  See `simple_featurize` for an example.\n","    # binary_bow_featurize,feature1,feature2,time_featurize,tech_featurize,prof_featurize,question_featurize,opinions_featurize,action_featurize,casual_featurize,personal_featurize,low_featurize,medium_featurize\n","    \n","  all_feats={}\n","  for feature in [binary_bow_featurize,feature2,question_featurize]:\n","    all_feats.update(feature(text))\n","  return all_feats"],"metadata":{"id":"nUUZOU-g0sCs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def confidence_intervals(accuracy, n, significance_level):\n","    critical_value=(1-significance_level)/2\n","    z_alpha=-1*norm.ppf(critical_value)\n","    se=math.sqrt((accuracy*(1-accuracy))/n)\n","    return accuracy-(se*z_alpha), accuracy+(se*z_alpha)"],"metadata":{"id":"L9gMAcGQnpZx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# def run(trainingFile, devFile, testFile, ordinal_values):\n","\n","\n","#     trainX, trainY, orig_trainY=load_ordinal_data(trainingFile, ordinal_values)\n","#     devX, devY, orig_devY=load_ordinal_data(devFile, ordinal_values)\n","#     testX, testY, orig_testY=load_ordinal_data(testFile, ordinal_values)\n","    \n","#     simple_classifier = OrdinalClassifier(ordinal_values, combiner_function, trainX, trainY, devX, devY, testX, testY, orig_trainY, orig_devY, orig_testY)\n","#     simple_classifier.train()\n","#     accuracy=simple_classifier.test()\n","\n","#     lower, upper=confidence_intervals(accuracy, len(devY[0]), .95)\n","#     print(\"Test accuracy for best dev model: %.3f, 95%% CIs: [%.3f %.3f]\\n\" % (accuracy, lower, upper))"],"metadata":{"id":"Vuwc7HV3nq90"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from sklearn.metrics import confusion_matrix\n","\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt"],"metadata":{"id":"cGL7y85eAleC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def run(trainingFile, devFile, testFile, ordinal_values):\n","\n","\n","    trainX, trainY, orig_trainY=load_ordinal_data(trainingFile, ordinal_values)\n","    devX, devY, orig_devY=load_ordinal_data(devFile, ordinal_values)\n","    testX, testY, orig_testY=load_ordinal_data(testFile, ordinal_values)\n","    #print(len(orig_testY))\n","    simple_classifier = OrdinalClassifier(ordinal_values, combiner_function, trainX, trainY, devX, devY, testX, testY, orig_trainY, orig_devY, orig_testY)\n","    simple_classifier.train()\n","    accuracy=simple_classifier.test()\n","\n","    lower, upper=confidence_intervals(accuracy, len(testY[0]), .95)\n","    print(\"Test accuracy for best dev model: %.3f, 95%% CIs: [%.3f %.3f]\\n\" % (accuracy, lower, upper))\n","\n","    #print(orig_testY)\n","\n","    #confusion matrix\n","\n","    pred_counts, pred_list = simple_classifier.prediction()\n","\n","    df = pd.DataFrame(orig_testY)\n","    \n","    print(pred_counts)\n","    print(orig_testY)\n","    print(type(orig_testY[0]), type(pred_list[0]))\n","\n","\n","    # cm = confusion_matrix(orig_testY, pred_list)\n","    # print(\"Confusion Matrix\\n\")\n","    # cm_df = pd.DataFrame(cm, index = [0, 1, 2], columns = [0, 1, 2])\n","    \n","    # #plot\n","    # plt.figure(figsize = (5, 4))\n","    # sns.heatmap(cm_df, annot = True)\n","    # plt.title('Confusion Matrix')\n","    # plt.ylabel('Actual')\n","    # plt.xlabel(\"prediction\")\n","    # plt.show()\n","\n","  \n","\n","\n","    print('0 for orig_testY:', orig_testY.count(\"low\"))\n","    print('1 for orig_testY:', orig_testY.count(\"medium\"))\n","    print('2 for orig_testY:', orig_testY.count(\"high\"))\n","    # print(pred_counts)\n","    # return pred_list"],"metadata":{"id":"TrKlPYfzItG3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# a = np.array([\"l\", \"m\", \"h\"])\n","# type(a)"],"metadata":{"id":"8juCi7rh0rdM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gid=23\n","trainingFile =  \"/gdrive/MyDrive/info 159 Project/ap4/train.txt\"\n","devFile = \"/gdrive/MyDrive/info 159 Project/ap4/dev.txt\"\n","testFile = \"/gdrive/MyDrive/info 159 Project/ap4/test.txt\"\n","    \n","# ordinal values must be in order *as strings* from smallest to largest, e.g.:\n","# ordinal_values=[\"G\", \"PG\", \"PG-13\", \"R\"]\n","\n","ordinal_values=[\"low\", \"medium\", \"high\"]\n","\n","run(trainingFile, devFile, testFile, ordinal_values)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FYEcn2efns5L","executionInfo":{"status":"ok","timestamp":1650599890474,"user_tz":420,"elapsed":3649,"user":{"displayName":"Jinglan Liu","userId":"09247368686056095984"}},"outputId":"e464aeff-ce1a-4e3f-9abd-843945714e9e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test accuracy for best dev model: 0.825, 95% CIs: [0.772 0.878]\n","\n","Counter({0: 152, 1: 34, 2: 14})\n","['low', 'low', 'low', 'low', 'medium', 'low', 'high', 'medium', 'low', 'low', 'medium', 'low', 'low', 'low', 'high', 'low', 'low', 'low', 'low', 'high', 'low', 'low', 'low', 'low', 'low', 'medium', 'low', 'low', 'low', 'low', 'low', 'low', 'low', 'low', 'low', 'medium', 'high', 'low', 'low', 'low', 'low', 'low', 'medium', 'low', 'low', 'low', 'medium', 'low', 'low', 'low', 'low', 'low', 'high', 'low', 'low', 'low', 'low', 'low', 'high', 'low', 'medium', 'low', 'high', 'medium', 'medium', 'low', 'low', 'low', 'medium', 'high', 'low', 'low', 'low', 'low', 'low', 'low', 'low', 'low', 'low', 'low', 'low', 'low', 'medium', 'low', 'low', 'low', 'medium', 'low', 'low', 'low', 'medium', 'medium', 'medium', 'low', 'low', 'low', 'low', 'low', 'high', 'low', 'low', 'medium', 'low', 'low', 'low', 'low', 'low', 'low', 'low', 'low', 'low', 'low', 'low', 'low', 'medium', 'low', 'high', 'low', 'low', 'low', 'medium', 'high', 'low', 'low', 'low', 'low', 'low', 'medium', 'low', 'high', 'low', 'low', 'low', 'low', 'low', 'low', 'low', 'high', 'low', 'low', 'medium', 'medium', 'low', 'medium', 'high', 'low', 'medium', 'low', 'low', 'low', 'medium', 'low', 'low', 'low', 'low', 'low', 'high', 'low', 'high', 'high', 'low', 'low', 'low', 'low', 'low', 'medium', 'low', 'low', 'low', 'low', 'low', 'low', 'low', 'low', 'low', 'high', 'low', 'high', 'low', 'low', 'low', 'low', 'low', 'low', 'low', 'low', 'high', 'low', 'medium', 'low', 'medium', 'low', 'low', 'low', 'low', 'low', 'medium', 'medium', 'low', 'low']\n","<class 'str'> <class 'numpy.int64'>\n","0 for orig_testY: 150\n","1 for orig_testY: 30\n","2 for orig_testY: 20\n"]}]},{"cell_type":"code","source":["orig_trainY = [\"low\", \"high\", \"medium\", \"low\"]"],"metadata":{"id":"JZpd8kIc3V60"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in range(len(orig_trainY)):\n","      if orig_trainY[i] == \"low\":\n","        orig_trainY[i] = 0\n","      elif orig_trainY[i] == \"medium\":\n","        orig_trainY[i] = 1\n","      else:\n","        orig_trainY[i] = 2"],"metadata":{"id":"RgQF4TWMnuYr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["type(orig_trainY[0])"],"metadata":{"id":"_jg9ATP9O8d_","executionInfo":{"status":"ok","timestamp":1650599806673,"user_tz":420,"elapsed":28,"user":{"displayName":"Jinglan Liu","userId":"09247368686056095984"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2f5fa301-5e07-41d4-a7c1-88a242efa06a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["int"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":[],"metadata":{"id":"MMZlbSgm-0cc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"pw06RSKz_PLC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["In our dataset, there are some texts that include rhetorical questions (e.g.\"How many times do I have to say EMAIL IT?\"). The true testY labeled them all as low because they are not actually asking a question, but the model predicted it as medium. It leads to biased in our model because the model cannot tell the difference between rhetorical questions and non-rhetorical questions, so it will categorized it into different label. Also, the text that is not English can also caused biases to our model, the model cannot tell whether the text is English or not, so it's harder for it to categorized. "],"metadata":{"id":"nxBcXYRLD-l9"}},{"cell_type":"markdown","source":["I think our dataset is very unbalance because the total length of the training dataset is 200, but over 50% of those are categorized as low, and only a small percentage of datasets are categorized as meidum or high. Since there too many low categories, it creates more noise to our dataset which will result in many mischaracterized label for low categories. I think our dataset is a good strategy for oversampling because we have too much low categories of in our dataset, so it might result in overfitting when we run our model. Using oversampling, we can transformed the minority dataset (e.g. medium and high) in our case, to have more examples of the dataset.\n","\n","Moreover, we can use class weight to improve the imbalance dataset, setting weight for three of our categories. We can apply smaller weight to high category because it has the most dataset, and apply bigger weight to medium and low dataset. So we can balance our datasets. "],"metadata":{"id":"irFJ_lXwncJG"}},{"cell_type":"code","source":[],"metadata":{"id":"TUP7JJ9H23t_"},"execution_count":null,"outputs":[]}]}